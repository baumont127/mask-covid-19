{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from matplotlib import patches\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from json import dump\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "cog_endpoint = os.getenv(\"COG_SERVICE_ENDPOINT\") + \"/face/v1.0/detect\"\n",
    "cog_key = os.getenv(\"COG_SERVICE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image...\n",
      "Image saved!\n"
     ]
    }
   ],
   "source": [
    "key = cv2. waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    try:\n",
    "        check, frame = webcam.read()\n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'):\n",
    "            \n",
    "            ### Entrez dans filename le nom du fichier .jpg correspondant à l'émotion que vous simulez (par exemple : happy.jpg) ###\n",
    "            cv2.imwrite(filename='normal.jpg', img=frame)\n",
    "            webcam.release()\n",
    "            cv2.waitKey(1650)\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Processing image...\")\n",
    "            \n",
    "            print(\"Image saved!\")\n",
    "        \n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            print(\"Turning off camera.\")\n",
    "            webcam.release()\n",
    "            print(\"Camera off.\")\n",
    "            print(\"Program ended.\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "    except(KeyboardInterrupt):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Image\n",
    "img = './normal.jpg'\n",
    "pil_image = Image.open(img, 'r')\n",
    "\n",
    "# Show Image\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(pil_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': cog_key,\n",
    "    'Content-Type': 'application/octet-stream'\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'returnFaceId': 'false',\n",
    "    'returnFaceLandmarks': 'true',\n",
    "    'returnFaceAttributes': 'age,gender,glasses,smile'\n",
    "}\n",
    "\n",
    "image_data = open(img, 'rb').read()\n",
    "\n",
    "\n",
    "\n",
    "response = requests.post(\n",
    "    cog_endpoint,\n",
    "    params=params,\n",
    "    headers=headers,\n",
    "    data=image_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'faceAttributes': {'age': 21.0,\n",
      "                     'gender': 'male',\n",
      "                     'glasses': 'NoGlasses',\n",
      "                     'smile': 0.0},\n",
      "  'faceLandmarks': {'eyeLeftBottom': {'x': 302.1, 'y': 154.7},\n",
      "                    'eyeLeftInner': {'x': 315.0, 'y': 149.3},\n",
      "                    'eyeLeftOuter': {'x': 288.1, 'y': 151.0},\n",
      "                    'eyeLeftTop': {'x': 301.8, 'y': 144.0},\n",
      "                    'eyeRightBottom': {'x': 385.4, 'y': 151.3},\n",
      "                    'eyeRightInner': {'x': 370.3, 'y': 148.5},\n",
      "                    'eyeRightOuter': {'x': 397.9, 'y': 145.8},\n",
      "                    'eyeRightTop': {'x': 383.7, 'y': 140.8},\n",
      "                    'eyebrowLeftInner': {'x': 323.7, 'y': 131.0},\n",
      "                    'eyebrowLeftOuter': {'x': 266.8, 'y': 139.6},\n",
      "                    'eyebrowRightInner': {'x': 360.4, 'y': 130.4},\n",
      "                    'eyebrowRightOuter': {'x': 413.9, 'y': 128.4},\n",
      "                    'mouthLeft': {'x': 314.6, 'y': 238.3},\n",
      "                    'mouthRight': {'x': 380.8, 'y': 236.1},\n",
      "                    'noseLeftAlarOutTip': {'x': 319.8, 'y': 194.3},\n",
      "                    'noseLeftAlarTop': {'x': 323.6, 'y': 179.5},\n",
      "                    'noseRightAlarOutTip': {'x': 370.6, 'y': 192.7},\n",
      "                    'noseRightAlarTop': {'x': 363.5, 'y': 177.4},\n",
      "                    'noseRootLeft': {'x': 330.9, 'y': 150.0},\n",
      "                    'noseRootRight': {'x': 357.1, 'y': 150.0},\n",
      "                    'noseTip': {'x': 343.0, 'y': 187.0},\n",
      "                    'pupilLeft': {'x': 302.1, 'y': 147.6},\n",
      "                    'pupilRight': {'x': 382.9, 'y': 146.2},\n",
      "                    'underLipBottom': {'x': 350.0, 'y': 248.6},\n",
      "                    'underLipTop': {'x': 348.7, 'y': 235.1},\n",
      "                    'upperLipBottom': {'x': 347.0, 'y': 235.0},\n",
      "                    'upperLipTop': {'x': 345.7, 'y': 226.1}},\n",
      "  'faceRectangle': {'height': 186, 'left': 252, 'top': 96, 'width': 186}}]\n"
     ]
    }
   ],
   "source": [
    "response_data = response.json()\n",
    "pprint.pprint(response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": { 
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(pil_image)\n",
    "for detected_face in response_data:\n",
    "    for landmark in detected_face['faceLandmarks'].values():\n",
    "        plt.scatter([landmark['x']], [landmark['y']], color='limegreen', s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_face_api(image_filepath):\n",
    "    params = {\n",
    "        'returnFaceId': 'false',\n",
    "        'returnFaceLandmarks': 'true',\n",
    "        'returnFaceAttributes': 'mask',\n",
    "        'detectionModel': 'detection_03'\n",
    "    }\n",
    "\n",
    "    image_data = open(image_filepath, 'rb').read()\n",
    "\n",
    "    response = requests.post(\n",
    "        cog_endpoint,\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "        data=image_data\n",
    "    )\n",
    "    response_data = response.json()\n",
    "    return response_data\n",
    "\n",
    "\n",
    "def plot_image_with_mask_label(image_filepath):\n",
    "    \n",
    "    response_data = call_face_api(image_filepath)\n",
    "    pil_image = Image.open(image_filepath, 'r')\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.imshow(pil_image)\n",
    "    \n",
    "    for detected_face in response_data:\n",
    "        rectangle_data =  detected_face['faceRectangle']\n",
    "        x = rectangle_data['left']\n",
    "        y = rectangle_data['top']\n",
    "        w = rectangle_data['width']\n",
    "        h = rectangle_data['height']\n",
    "        if detected_face['faceAttributes']['mask']['type'] == 'noMask':\n",
    "            label_str = \"No Mask\"\n",
    "            color_str = \"red\"\n",
    "        else:\n",
    "            label_str = \"Wearing Mask\"\n",
    "            color_str = \"limegreen\"\n",
    "        rect = patches.Rectangle(\n",
    "            [x, y], w, h,\n",
    "            linewidth=2, edgecolor=color_str, facecolor='none'\n",
    "        )\n",
    "        ax = plt.gca()\n",
    "        plt.text(\n",
    "            x,\n",
    "            y + h + 60,\n",
    "            label_str,\n",
    "            size=15,\n",
    "            c=color_str\n",
    "        )\n",
    "    print(detected_face)\n",
    "    ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faceRectangle': {'top': 59, 'left': 257, 'width': 170, 'height': 226}, 'faceLandmarks': {'pupilLeft': {'x': 302.3, 'y': 151.2}, 'pupilRight': {'x': 385.1, 'y': 147.4}, 'noseTip': {'x': 344.0, 'y': 188.3}, 'mouthLeft': {'x': 316.4, 'y': 236.5}, 'mouthRight': {'x': 374.4, 'y': 234.4}, 'eyebrowLeftOuter': {'x': 278.8, 'y': 132.1}, 'eyebrowLeftInner': {'x': 320.4, 'y': 130.1}, 'eyeLeftOuter': {'x': 287.4, 'y': 152.7}, 'eyeLeftTop': {'x': 303.7, 'y': 145.5}, 'eyeLeftBottom': {'x': 300.5, 'y': 155.4}, 'eyeLeftInner': {'x': 317.5, 'y': 151.1}, 'eyebrowRightInner': {'x': 362.3, 'y': 129.9}, 'eyebrowRightOuter': {'x': 408.8, 'y': 130.6}, 'eyeRightInner': {'x': 370.6, 'y': 149.2}, 'eyeRightTop': {'x': 383.1, 'y': 141.5}, 'eyeRightBottom': {'x': 386.4, 'y': 151.6}, 'eyeRightOuter': {'x': 400.4, 'y': 147.3}, 'noseRootLeft': {'x': 330.4, 'y': 154.5}, 'noseRootRight': {'x': 355.5, 'y': 152.6}, 'noseLeftAlarTop': {'x': 325.8, 'y': 180.6}, 'noseRightAlarTop': {'x': 361.7, 'y': 178.7}, 'noseLeftAlarOutTip': {'x': 320.4, 'y': 197.4}, 'noseRightAlarOutTip': {'x': 368.5, 'y': 196.5}, 'upperLipTop': {'x': 347.0, 'y': 228.2}, 'upperLipBottom': {'x': 345.4, 'y': 234.4}, 'underLipTop': {'x': 345.2, 'y': 237.5}, 'underLipBottom': {'x': 346.1, 'y': 246.9}}, 'faceAttributes': {'mask': {'type': 'noMask', 'noseAndMouthCovered': False}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image_with_mask_label('./normal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "\n",
    "def plot_image_with_mask_label(image_filepath):\n",
    "    \n",
    "    response_data = call_face_api(image_filepath)\n",
    "    \n",
    "    for detected_face in response_data:\n",
    "        if detected_face['faceAttributes']['mask']['type'] == 'noMask':\n",
    "            lst.append(0)\n",
    "        else:\n",
    "            lst.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_with_mask_label('./normal.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all_mask.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_img = []\n",
    "\n",
    "for path in df['image path']:\n",
    "        \n",
    "    img = Image.open(path).convert(\"L\")\n",
    "    pix = np.reshape(np.array(img, dtype='uint16'),(224*224))\n",
    "    arr_img.append(pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    310\n",
       "1    310\n",
       "Name: values, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['values'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "\n",
    "def plot_image_with_mask_label(image_filepath):\n",
    "    \n",
    "    response_data = call_face_api(image_filepath)\n",
    "    \n",
    "    for detected_face in response_data:\n",
    "        time.sleep(5) \n",
    "        if detected_face['faceAttributes']['mask']['type'] == 'noMask':\n",
    "            lst.append(0)\n",
    "        else:\n",
    "            lst.append(1)\n",
    "\n",
    "for path in df_test['image path']:\n",
    "    plot_image_with_mask_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       310\n",
      "           1       0.93      1.00      0.96       310\n",
      "\n",
      "    accuracy                           0.96       620\n",
      "   macro avg       0.96      0.96      0.96       620\n",
      "weighted avg       0.96      0.96      0.96       620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(df_test['values'], lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {

      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(df_test['values'], lst)\n",
    "sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c94b1f83e087494cd9bacb991a9ab9d231372eea1fd1c18c41987e5dfa60d667"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
